{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             lingala  \\\n",
      "0    Na ebandeli Nzambe azalisaki likoló mpe mabele.   \n",
      "1  Kasi mabele ezalaki kaka bongobongo mpe ezalak...   \n",
      "2  Mpe Nzambe alobaki ete: “Pole ezala.” Bongo po...   \n",
      "3  Nsima na yango, Nzambe amonaki ete pole ezalak...   \n",
      "4  Nzambe abengaki pole Moi, kasi abengaki molili...   \n",
      "5  Na nsima, Nzambe alobaki ete: “Etando ezala ka...   \n",
      "\n",
      "                                             english  \n",
      "0  In the beginning God created the heavens and t...  \n",
      "1  Now the earth was formless and desolate, and t...  \n",
      "2  And God said: “Let there be light.” Then there...  \n",
      "3  After that God saw that the light was good, an...  \n",
      "4  God called the light Day, but the darkness he ...  \n",
      "5  Then God said: “Let there be an expanse betwee...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(31194, 2)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"verse_pairs.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(dataset.head(6))\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 lingala  \\\n",
      "0        Na ebandeli Nzambe azalisaki likoló mpe mabele.   \n",
      "1      Kasi mabele ezalaki kaka bongobongo mpe ezalak...   \n",
      "2      Mpe Nzambe alobaki ete: “Pole ezala.” Bongo po...   \n",
      "3      Nsima na yango, Nzambe amonaki ete pole ezalak...   \n",
      "4      Nzambe abengaki pole Moi, kasi abengaki molili...   \n",
      "...                                                  ...   \n",
      "31189  Elimo ná mwasi ya libala bazali kaka koloba et...   \n",
      "31190  “Nazali koyebisa moto nyonso oyo azali koyoka ...   \n",
      "31191  mpe soki moto alongoli liloba moko na maloba y...   \n",
      "31192  “Moto oyo azali kotatola makambo oyo alobi ete...   \n",
      "31193      Boboto monene ya Nkolo Yesu ezala na basantu.   \n",
      "\n",
      "                                                 english  \n",
      "0      In the beginning God created the heavens and t...  \n",
      "1      Now the earth was formless and desolate, and t...  \n",
      "2      And God said: “Let there be light.” Then there...  \n",
      "3      After that God saw that the light was good, an...  \n",
      "4      God called the light Day, but the darkness he ...  \n",
      "...                                                  ...  \n",
      "31189  And the spirit and the bride keep on saying, “...  \n",
      "31190  â€œI am bearing witness to everyone who hears ...  \n",
      "31191  and if anyone takes anything away from the wor...  \n",
      "31192  “The one who bears witness of these things say...  \n",
      "31193  May the undeserved kindness of the Lord Jesus ...  \n",
      "\n",
      "[31194 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda_3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda_3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda_3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TOKENIZATION\n",
    "!pip install tensorflow\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tokenizer for Lingala and English\n",
    "lingala_tokenizer = Tokenizer()\n",
    "english_tokenizer = Tokenizer()\n",
    "\n",
    "# Fit tokenizers on text data\n",
    "lingala_tokenizer.fit_on_texts(dataset['lingala'])\n",
    "english_tokenizer.fit_on_texts(dataset['english'])\n",
    "\n",
    "# Convert text data to sequences of tokens\n",
    "lingala_sequences = lingala_tokenizer.texts_to_sequences(dataset['lingala'])\n",
    "english_sequences = english_tokenizer.texts_to_sequences(dataset['english'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PADDING SEQUENCES - To ensure all sequences have the same length, you'll need to pad the sequences. \n",
    "# Keras provides utilities for padding sequences using the pad_sequences function\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define maximum sequence length\n",
    "max_sequence_length = 50  # Adjust as needed\n",
    "\n",
    "# Pad sequences\n",
    "padded_lingala_sequences = pad_sequences(lingala_sequences, maxlen=max_sequence_length, padding='post')\n",
    "padded_english_sequences = pad_sequences(english_sequences, maxlen=max_sequence_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shapes: (25266, 50) (25266, 50)\n",
      "Validation set shapes: (2808, 50) (2808, 50)\n",
      "Test set shapes: (3120, 50) (3120, 50)\n"
     ]
    }
   ],
   "source": [
    "#Train-Validation-Test Split\n",
    "#Split the dataset into training, validation, and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "train_lingala, test_lingala, train_english, test_english = train_test_split(padded_lingala_sequences, \n",
    "                                                                            padded_english_sequences, \n",
    "                                                                            test_size=0.1, \n",
    "                                                                            random_state=42)\n",
    "train_lingala, val_lingala, train_english, val_english = train_test_split(train_lingala, \n",
    "                                                                          train_english, \n",
    "                                                                          test_size=0.1, \n",
    "                                                                          random_state=42)\n",
    "\n",
    "# Check the shapes of the datasets\n",
    "print(\"Train set shapes:\", train_lingala.shape, train_english.shape)\n",
    "print(\"Validation set shapes:\", val_lingala.shape, val_english.shape)\n",
    "print(\"Test set shapes:\", test_lingala.shape, test_english.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement positional encoding to provide positional information to the model.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def positional_encoding(max_seq_len, d_model):\n",
    "    pos_enc = np.zeros((max_seq_len, d_model))\n",
    "    for pos in range(max_seq_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            pos_enc[pos, i] = np.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "            pos_enc[pos, i+1] = np.cos(pos / (10000 ** ((2 * (i+1))/d_model)))\n",
    "    return pos_enc\n",
    "\n",
    "# Define maximum sequence length and model dimension\n",
    "max_seq_len = 50  # Same as the padded sequence length\n",
    "d_model = 128  # Adjust as needed\n",
    "\n",
    "# Generate positional encodings\n",
    "positional_encoding_matrix = positional_encoding(max_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda_3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\User\\anaconda_3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " lingala_input (InputLayer)  [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " lingala_embedding (Embeddi  (None, 50, 128)              2269056   ['lingala_input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " add (Add)                   (50, 50, 128)                0         ['lingala_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (50, 50, 128)                66048     ['add[0][0]',                 \n",
      " iHeadAttention)                                                     'add[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (50, 50, 128)                0         ['multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " add_2 (Add)                 (50, 50, 128)                0         ['add[0][0]',                 \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (50, 50, 128)                256       ['add_2[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (50, 50, 512)                66048     ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (50, 50, 128)                65664     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (50, 50, 128)                0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (50, 50, 128)                0         ['layer_normalization[0][0]', \n",
      "                                                                     'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (50, 50, 128)                256       ['add_3[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (50, 50, 128)                66048     ['layer_normalization_1[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (50, 50, 128)                0         ['multi_head_attention_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (50, 50, 128)                0         ['layer_normalization_1[0][0]'\n",
      "                                                                    , 'dropout_2[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (50, 50, 128)                256       ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (50, 50, 512)                66048     ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (50, 50, 128)                65664     ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (50, 50, 128)                0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (50, 50, 128)                0         ['layer_normalization_2[0][0]'\n",
      "                                                                    , 'dropout_3[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (50, 50, 128)                256       ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (50, 50, 128)                66048     ['layer_normalization_3[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (50, 50, 128)                0         ['multi_head_attention_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (50, 50, 128)                0         ['layer_normalization_3[0][0]'\n",
      "                                                                    , 'dropout_4[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (50, 50, 128)                256       ['add_6[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (50, 50, 512)                66048     ['layer_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (50, 50, 128)                65664     ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (50, 50, 128)                0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (50, 50, 128)                0         ['layer_normalization_4[0][0]'\n",
      "                                                                    , 'dropout_5[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (50, 50, 128)                256       ['add_7[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (50, 50, 128)                66048     ['layer_normalization_5[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (50, 50, 128)                0         ['multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " english_input (InputLayer)  [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (50, 50, 128)                0         ['layer_normalization_5[0][0]'\n",
      "                                                                    , 'dropout_6[0][0]']          \n",
      "                                                                                                  \n",
      " english_embedding (Embeddi  (None, 50, 128)              2204160   ['english_input[0][0]']       \n",
      " ng)                                                                                              \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (50, 50, 128)                256       ['add_8[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (50, 50, 128)                0         ['english_embedding[0][0]']   \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (50, 50, 512)                66048     ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (50, 50, 128)                66048     ['add_1[0][0]',               \n",
      " ltiHeadAttention)                                                   'add_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (50, 50, 128)                65664     ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (50, 50, 128)                0         ['multi_head_attention_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (50, 50, 128)                0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " add_10 (Add)                (50, 50, 128)                0         ['add_1[0][0]',               \n",
      "                                                                     'dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (50, 50, 128)                0         ['layer_normalization_6[0][0]'\n",
      "                                                                    , 'dropout_7[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (50, 50, 128)                256       ['add_10[0][0]']              \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (50, 50, 128)                256       ['add_9[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (50, 50, 128)                66048     ['layer_normalization_8[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (50, 50, 128)                0         ['multi_head_attention_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_11 (Add)                (50, 50, 128)                0         ['layer_normalization_8[0][0]'\n",
      "                                                                    , 'dropout_9[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (50, 50, 128)                256       ['add_11[0][0]']              \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (50, 50, 512)                66048     ['layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (50, 50, 128)                65664     ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (50, 50, 128)                0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " add_12 (Add)                (50, 50, 128)                0         ['layer_normalization_9[0][0]'\n",
      "                                                                    , 'dropout_10[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (50, 50, 128)                256       ['add_12[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (50, 50, 128)                66048     ['layer_normalization_10[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (50, 50, 128)                0         ['multi_head_attention_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_13 (Add)                (50, 50, 128)                0         ['layer_normalization_10[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (50, 50, 128)                256       ['add_13[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  (50, 50, 128)                66048     ['layer_normalization_11[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (50, 50, 128)                0         ['multi_head_attention_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_14 (Add)                (50, 50, 128)                0         ['layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (50, 50, 128)                256       ['add_14[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (50, 50, 512)                66048     ['layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (50, 50, 128)                65664     ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (50, 50, 128)                0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " add_15 (Add)                (50, 50, 128)                0         ['layer_normalization_12[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (50, 50, 128)                256       ['add_15[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (50, 50, 128)                66048     ['layer_normalization_13[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)        (50, 50, 128)                0         ['multi_head_attention_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_16 (Add)                (50, 50, 128)                0         ['layer_normalization_13[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_14[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (50, 50, 128)                256       ['add_16[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  (50, 50, 128)                66048     ['layer_normalization_14[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)        (50, 50, 128)                0         ['multi_head_attention_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_17 (Add)                (50, 50, 128)                0         ['layer_normalization_14[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_15[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (50, 50, 128)                256       ['add_17[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (50, 50, 512)                66048     ['layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (50, 50, 128)                65664     ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)        (50, 50, 128)                0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " add_18 (Add)                (50, 50, 128)                0         ['layer_normalization_15[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_16[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (50, 50, 128)                256       ['add_18[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (M  (50, 50, 128)                66048     ['layer_normalization_16[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)        (50, 50, 128)                0         ['multi_head_attention_10[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_19 (Add)                (50, 50, 128)                0         ['layer_normalization_16[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_17[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (50, 50, 128)                256       ['add_19[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (M  (50, 50, 128)                66048     ['layer_normalization_17[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)        (50, 50, 128)                0         ['multi_head_attention_11[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " add_20 (Add)                (50, 50, 128)                0         ['layer_normalization_17[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_18[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (50, 50, 128)                256       ['add_20[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (50, 50, 512)                66048     ['layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (50, 50, 128)                65664     ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)        (50, 50, 128)                0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " add_21 (Add)                (50, 50, 128)                0         ['layer_normalization_18[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'dropout_19[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (50, 50, 128)                256       ['add_21[0][0]']              \n",
      " yerNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (50, 50, 17220)              2221380   ['layer_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8545988 (32.60 MB)\n",
      "Trainable params: 8545988 (32.60 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Transformer architecture using Keras layers\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Dropout, Dense, LayerNormalization, MultiHeadAttention, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (max_seq_len,)\n",
    "\n",
    "# Input layers for Lingala and English sequences\n",
    "lingala_input = Input(shape=input_shape, name='lingala_input')\n",
    "english_input = Input(shape=input_shape, name='english_input')\n",
    "\n",
    "# Embedding layers for Lingala and English\n",
    "lingala_embedding = Embedding(input_dim=len(lingala_tokenizer.word_index)+1, output_dim=d_model, input_length=max_seq_len, name='lingala_embedding')(lingala_input)\n",
    "english_embedding = Embedding(input_dim=len(english_tokenizer.word_index)+1, output_dim=d_model, input_length=max_seq_len, name='english_embedding')(english_input)\n",
    "\n",
    "# Add positional encoding to the embeddings\n",
    "lingala_embedding_with_pos = Add()([lingala_embedding, positional_encoding_matrix])\n",
    "english_embedding_with_pos = Add()([english_embedding, positional_encoding_matrix])\n",
    "\n",
    "# Encoder layers\n",
    "num_layers = 4  # Adjust as needed\n",
    "encoder_output = lingala_embedding_with_pos\n",
    "for _ in range(num_layers):\n",
    "    # Self-attention layer\n",
    "    self_attention = MultiHeadAttention(num_heads=8, key_dim=d_model//8)(encoder_output, encoder_output)\n",
    "    self_attention = Dropout(0.1)(self_attention)\n",
    "    self_attention = Add()([encoder_output, self_attention])\n",
    "    self_attention = LayerNormalization(epsilon=1e-6)(self_attention)\n",
    "    \n",
    "    # Feed-forward neural network\n",
    "    ffn = Dense(512, activation='relu')(self_attention)\n",
    "    ffn = Dense(d_model)(ffn)\n",
    "    ffn = Dropout(0.1)(ffn)\n",
    "    ffn = Add()([self_attention, ffn])\n",
    "    encoder_output = LayerNormalization(epsilon=1e-6)(ffn)\n",
    "\n",
    "# Decoder layers\n",
    "decoder_output = english_embedding_with_pos\n",
    "for _ in range(num_layers):\n",
    "    # Self-attention layer\n",
    "    self_attention = MultiHeadAttention(num_heads=8, key_dim=d_model//8)(decoder_output, decoder_output)\n",
    "    self_attention = Dropout(0.1)(self_attention)\n",
    "    self_attention = Add()([decoder_output, self_attention])\n",
    "    self_attention = LayerNormalization(epsilon=1e-6)(self_attention)\n",
    "    \n",
    "    # Encoder-decoder attention layer\n",
    "    enc_dec_attention = MultiHeadAttention(num_heads=8, key_dim=d_model//8)(self_attention, encoder_output)\n",
    "    enc_dec_attention = Dropout(0.1)(enc_dec_attention)\n",
    "    enc_dec_attention = Add()([self_attention, enc_dec_attention])\n",
    "    enc_dec_attention = LayerNormalization(epsilon=1e-6)(enc_dec_attention)\n",
    "    \n",
    "    # Feed-forward neural network\n",
    "    ffn = Dense(512, activation='relu')(enc_dec_attention)\n",
    "    ffn = Dense(d_model)(ffn)\n",
    "    ffn = Dropout(0.1)(ffn)\n",
    "    ffn = Add()([enc_dec_attention, ffn])\n",
    "    decoder_output = LayerNormalization(epsilon=1e-6)(ffn)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(len(english_tokenizer.word_index)+1, activation='softmax')(decoder_output)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[lingala_input, english_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Loss Function\n",
    "#Since this is a Multiclass classification task (predicting the next word in the translated sequence), \n",
    "# you can use categorical cross-entropy as the loss function.\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "loss_function = 'sparse_categorical_crossentropy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the Model\n",
    "#Compile the model with an optimizer like Adam and the defined loss function. \n",
    "#Specify also additional metrics to monitor during training, such as accuracy.\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(learning_rate=0.0001)  # You can adjust the learning rate as needed\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model\n",
    "#Train the Transformer model on the training data. Monitor training progress using metrics like validation loss. \n",
    "#Specify also the batch size and number of epochs for training.\n",
    "\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 64\n",
    "num_epochs = 10  # You can adjust the number of epochs as needed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'add' (type Add).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [64,50,128] vs. [50,1,128] [Op:AddV2] name: \n\nCall arguments received by layer 'add' (type Add):\n  • inputs=['tf.Tensor(shape=(64, 50, 128), dtype=float32)', 'tf.Tensor(shape=(50, 128), dtype=float32)']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlingala_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_lingala\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_english\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_english\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Keep the target data as is\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlingala_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_lingala\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_english\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_english\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Keep the validation target data as is\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda_3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda_3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'add' (type Add).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [64,50,128] vs. [50,1,128] [Op:AddV2] name: \n\nCall arguments received by layer 'add' (type Add):\n  • inputs=['tf.Tensor(shape=(64, 50, 128), dtype=float32)', 'tf.Tensor(shape=(50, 128), dtype=float32)']"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Enable eager execution\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    {'lingala_input': train_lingala, 'english_input': train_english},\n",
    "    train_english,  # Keep the target data as is\n",
    "    validation_data=({'lingala_input': val_lingala, 'english_input': val_english}, val_english),  # Keep the validation target data as is\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
